{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKMrfcVlPdeW",
        "outputId": "0717c768-71e5-4009-f639-c33fa1ad59ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Описание проекта"
      ],
      "metadata": {
        "id": "A96P6dWVXhcV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ретейлер \"Лента\" хочет научиться оптимизировать производство товаров. Необходимо построить модели, которые будут прогнозировать спрос на товары, чтобы не было недостатка и избытка в магазинах."
      ],
      "metadata": {
        "id": "hBb_JNA8XkE3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# План проекта"
      ],
      "metadata": {
        "id": "jCzWz5O6XoW2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Изучить данные, проверить на наличие аномалий, неправильных типов и т.д. Отчистить данные от них (при необходимости);\n",
        "2. Визуализировать полученные данные и сделать вывод;\n",
        "3. Обучить модели с подбором параметров и выбрать среди них наилучшую;\n",
        "4. Протестировать модель с лучшим показателем метрики и сделать выводы по итогам работы;\n",
        "\n",
        "Необходимые библиотеки:"
      ],
      "metadata": {
        "id": "zKhqInCdXpsu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJSLsbFsX0AS",
        "outputId": "e2c09e0c-8fa7-4e6d-ae11-ab9fd29a363f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting catboost\n",
            "  Downloading catboost-1.2.2-cp310-cp310-manylinux2014_x86_64.whl (98.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.7/98.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n",
        "from keras.preprocessing.sequence import TimeseriesGenerator\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "state = 17"
      ],
      "metadata": {
        "id": "N7sGlRaQPeMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "U06N4IPEX7kj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EDA"
      ],
      "metadata": {
        "id": "XTY6EV1NX9G-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# данные по магазинам\n",
        "st_df = pd.read_csv(r'/content/drive/MyDrive/sp_sales_task/st_df.csv')\n",
        "\n",
        "# данные по иерархии товаров\n",
        "pr_df = pd.read_csv(r'/content/drive/MyDrive/sp_sales_task/pr_df.csv')\n",
        "\n",
        "# данные по продажам\n",
        "sales_df_train = pd.read_csv(r'/content/drive/MyDrive/sp_sales_task/sales_df_train.csv')\n",
        "\n",
        "# календарь\n",
        "calendar = pd.read_csv(r'/content/drive/MyDrive/sp_sales_task/holidays_covid_calendar.csv')\n",
        "\n",
        "# мерджим флаг активности\n",
        "sales_df_train = pd.merge(sales_df_train, st_df[['st_id','st_is_active']], on='st_id', how='left')\n",
        "\n",
        "# выбираем только рабочие магазины\n",
        "sales_df_train = sales_df_train[sales_df_train['st_is_active'] == 1]\n",
        "\n",
        "# избавляемся от возвратных позиций\n",
        "sales_df_train = sales_df_train[sales_df_train['pr_sales_in_rub'] >= 0]\n",
        "\n",
        "# создал переменную, куда скопировал основной дф\n",
        "sales_df_train_1 = sales_df_train\n",
        "\n",
        "# удаляем все строки, где объем продаж = 0\n",
        "sales_df_train_1 = sales_df_train_1[sales_df_train_1['pr_sales_in_units'] != 0]\n",
        "\n",
        "# удаляю строки, где сумма продаж по 1 позиции меньше 15 тыс. руб.\n",
        "sales_df_train_1 = sales_df_train_1[sales_df_train_1['pr_sales_in_rub'] < 15000]\n",
        "\n",
        "# агрегирую продажи по магазинам\n",
        "sales_df_train_1['price'] = sales_df_train_1['pr_sales_in_rub'] / sales_df_train_1['pr_sales_in_units']\n",
        "\n",
        "# агрегирую продажи по магазинам\n",
        "gr_shop = sales_df_train_1.groupby('st_id').agg({'pr_sales_in_rub':'sum', 'pr_sales_in_units':'sum'}).reset_index()\n",
        "\n",
        "# информация по суммарным продажам по магазинам\n",
        "gr_shop.sort_values(by='pr_sales_in_units')"
      ],
      "metadata": {
        "id": "8mNhnUCDPfnX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# находим стоимость за единицу продукции\n",
        "sales_df_train_1['price'] = sales_df_train_1['pr_sales_in_rub'] / sales_df_train_1['pr_sales_in_units']\n",
        "\n",
        "# вывожу строки, где цена = 0\n",
        "sales_df_train_1[sales_df_train_1['price'] == 0].head()\n",
        "\n",
        "# удаляю строки, где price = 0\n",
        "sales_df_train_1.drop(sales_df_train_1[sales_df_train_1['price'] == 0].index, inplace=True)\n",
        "\n",
        "# небольшие махинации для дальнейшего метода merge\n",
        "sales_df_train_1.drop(columns='st_is_active', inplace=True)\n",
        "calendar['calday'] = calendar['calday'].astype(str)\n",
        "sales_df_train_1['date'] = pd.to_datetime(sales_df_train_1['date']).dt.strftime('%Y%m%d')\n",
        "\n",
        "sales_df_train_1 = pd.merge(sales_df_train_1, calendar, left_on='date',\n",
        "                          right_on='calday', how='left')\n",
        "\n",
        "# приводим в приличный вид\n",
        "sales_df_train_1.drop(columns='date_y', inplace=True)\n",
        "sales_df_train_1.rename(columns={'date_x':'date'}, inplace=True)\n",
        "\n",
        "# добавляем фич с номером месяца\n",
        "sales_df_train_1['month'] = sales_df_train_1['calday'].str[4:6]\n",
        "\n",
        "# добавляем фичи с товарной иерархией\n",
        "sales_df_train_1 = pd.merge(sales_df_train_1, pr_df, on='pr_sku_id', how='left')\n",
        "\n",
        "# добавляем фичи с данными по магазинам\n",
        "sales_df_train_1 = pd.merge(sales_df_train_1, st_df, on='st_id', how='left')\n",
        "\n",
        "# описательная статистика продаж без промо\n",
        "sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 0]['pr_sales_in_rub'].describe()"
      ],
      "metadata": {
        "id": "ret8AnKKYZFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# описательная статистика продаж с промо\n",
        "sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 1]['pr_sales_in_rub'].describe()"
      ],
      "metadata": {
        "id": "ceTEJtVZY4V6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Обычные продажи в %:',\n",
        "      round(sales_df_train_1['pr_sales_type_id'].value_counts()[0]/len(sales_df_train_1) * 100))\n",
        "print('Промо продажи в %:',\n",
        "      round(sales_df_train_1['pr_sales_type_id'].value_counts()[1]/len(sales_df_train_1) * 100))"
      ],
      "metadata": {
        "id": "rTfxFcp8Y7Z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# гистограммы\n",
        "sns.distplot(sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 1]['pr_sales_in_rub'],\n",
        "             label='С промо', color='red', bins=30)\n",
        "\n",
        "sns.distplot(sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 0]['pr_sales_in_rub'],\n",
        "             label='Без промо', color='black', bins=30)\n",
        "\n",
        "plt.xlabel('Продажи в рублях')\n",
        "plt.title('Гистограммы продаж с/без промо')\n",
        "plt.xlim(0, 10000)\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "nT9e7dPHY8hG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# диаграммы размаха\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.boxplot(sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 0]['pr_sales_in_rub'],\n",
        "           positions=[1], labels=['Без промо'])\n",
        "\n",
        "ax.boxplot(sales_df_train_1[sales_df_train_1['pr_sales_type_id'] == 1]['pr_sales_in_rub'],\n",
        "           positions=[2], labels=['С промо'])\n",
        "\n",
        "ax.set_xlabel('Типы продаж')\n",
        "ax.set_title('Диаграммы размаха продаж с/без промо')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vgH2mghjZAXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# продажи по месяцам\n",
        "month_sales = sales_df_train_1.groupby(['year', 'month']).agg({'pr_sales_in_units':'sum'}).reset_index()"
      ],
      "metadata": {
        "id": "v1dMMknLZCha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 4))\n",
        "plt.bar(month_sales['month'], month_sales['pr_sales_in_units'], color='black')\n",
        "plt.title(\"Сумма продаж за 22-23г. (в шт.)\")\n",
        "plt.xlabel(\"Месяц\")\n",
        "plt.ylabel(\"Кол-во товара\")"
      ],
      "metadata": {
        "id": "Chn4-f7ZZDBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# добавляем столбик с значением выходного дня (1 - день выходной, 0 - рабочий)\n",
        "sales_df_train_1['weekend'] = 0\n",
        "sales_df_train_1.loc[sales_df_train_1['weekday'].isin([6, 7]), 'weekend'] = 1"
      ],
      "metadata": {
        "id": "4EYbdZ9UZEvy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df_train_1.groupby('weekend').agg({'pr_sales_in_units':'sum'}).reset_index()"
      ],
      "metadata": {
        "id": "kM5cQ78zZH6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "В процессе EDA было выполнено:\n",
        "\n",
        "- Отобраны только активные магазины по флагу;\n",
        "- Были удалены возвратные позиции, строки с объемом продаж = 0, строки с продажами более 15 тыс. руб.;\n",
        "- Были удалены магазины (3 шт.), где продажи были слишком малы по сравнению с другими магазинами;\n",
        "- Удалены также строки, где цена = 0;\n",
        "- Добавлены фичи: номер месяца, товарная иерархия, данные по магазинам;\n",
        "- Из описательной статистики по продажам можно сделать выводы:\n",
        "  1. Средняя покупка без промо - 532 руб., с промо 707 руб.;\n",
        "  2. Лишь 40% продаж приходится на промо%.\n",
        "- Построены гистрограммы продаж из которых видно, что большая часть продажь - до 2 тыс. руб.;\n",
        "- На диаграммах размаха видно, что есть много аномалий, однако не все аномалии - плохо, принято решение оставить эти выбросы;\n",
        "- Из графика \"Сумма продаж за...\" можно сделать вывод, что в Декабре продажи резко подскакивают, также рост продаж отмечается и в весенний период, когда много праздников и теплеет, летом замечен спад. Вероятно, люди уезжают кто куда и спрос на товары падает;\n",
        "- Около 65% продаж приходится на рабочий день.\n",
        "\n"
      ],
      "metadata": {
        "id": "9y9NSnDcZIcN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Обучение моделей"
      ],
      "metadata": {
        "id": "OaFYxGFaZmqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sales_df_train_1.drop(columns=['pr_sales_type_id', 'pr_promo_sales_in_units', 'pr_sales_in_rub', 'pr_promo_sales_in_rub', 'price', 'st_is_active'], inplace=True)"
      ],
      "metadata": {
        "id": "iXdQwBW1P20c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression"
      ],
      "metadata": {
        "id": "qv3XKrjvQfgg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "categorical_features = sales_df_train_1.select_dtypes(include='object')\n",
        "\n",
        "features = sales_df_train_1.drop(columns=[\"pr_sales_in_units\"])\n",
        "target = sales_df_train_1[\"pr_sales_in_units\"]\n",
        "\n",
        "label_encoders = {}\n",
        "for feature in categorical_features:\n",
        "    label_encoder = LabelEncoder()\n",
        "    features[feature] = label_encoder.fit_transform(features[feature])\n",
        "    label_encoders[feature] = label_encoder\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "features_scaled = scaler.fit_transform(features)\n",
        "\n",
        "# Модель линейной регрессии\n",
        "model = LinearRegression()\n",
        "\n",
        "# Количество временных разбиений (k)\n",
        "n_splits = 5\n",
        "\n",
        "# Создание объекта TimeSeriesSplit для временной кросс-валидации\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "\n",
        "# Инициализация переменной для хранения WAPE на каждой итерации\n",
        "wapes = []\n",
        "\n",
        "# Цикл для временной кросс-валидации\n",
        "for train_index, test_index in tscv.split(features_scaled):\n",
        "    # Разделение масштабированных данных на обучающий и тестовый наборы\n",
        "    features_train, features_test = features_scaled[train_index], features_scaled[test_index]\n",
        "    target_train, target_test = target.iloc[train_index], target.iloc[test_index]\n",
        "\n",
        "    # Обучение модели на обучающем наборе\n",
        "    model.fit(features_train, target_train)\n",
        "\n",
        "    # Прогноз на тестовом наборе\n",
        "    target_pred = model.predict(features_test)\n",
        "\n",
        "    # Расчет WAPE\n",
        "    wape = np.sum(np.abs(target_test - target_pred)) / np.sum(np.abs(target_test))\n",
        "    wapes.append(wape)\n",
        "\n",
        "# Вывод среднего WAPE на всех итерациях кросс-валидации\n",
        "print(\"Средний WAPE на кросс-валидации:\", np.mean(wapes))"
      ],
      "metadata": {
        "id": "amoxAR6JQi89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM Model"
      ],
      "metadata": {
        "id": "zqbESgoWSXtj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# Разделение данных на обучающий и тестовый наборы (по времени)\n",
        "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, shuffle=False)\n",
        "\n",
        "# Выбор категориальных признаков\n",
        "cat_cols = sales_df_train_1.select_dtypes(include='object')\n",
        "\n",
        "# Преобразование категориальных признаков с использованием OrdinalEncoder\n",
        "ord_enc = OrdinalEncoder().fit(features_train[cat_cols.columns])\n",
        "features_train[cat_cols.columns] = ord_enc.transform(features_train[cat_cols.columns])\n",
        "features_test[cat_cols.columns] = ord_enc.fit_transform(features_test[cat_cols.columns])\n",
        "\n",
        "# Масштабирование признаков с использованием StandardScaler\n",
        "scaler = StandardScaler().fit(features_train)\n",
        "features_train = scaler.transform(features_train)\n",
        "features_test = scaler.transform(features_test)\n",
        "\n",
        "# Параметры для создания временных последовательностей\n",
        "n_input = 1\n",
        "n_features = features_train.shape[1]\n",
        "\n",
        "# Создание генератора временных последовательностей с использованием TimeseriesGenerator\n",
        "generator = TimeseriesGenerator(features_train, target_train, length=n_input, batch_size=1)\n",
        "\n",
        "# Параметры модели LSTM\n",
        "n_steps = 14\n",
        "n_features = 1\n",
        "\n",
        "# Изменение формы данных для модели LSTM\n",
        "feat_train = features_train.reshape(features_train.shape[0], features_train.shape[1], n_features)\n",
        "target_train = np.array(target_train)\n",
        "\n",
        "# Создание модели LSTM\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(200, activation='relu', input_shape=(features_train.shape[1], n_features), return_sequences=True))\n",
        "lstm_model.add(LSTM(32, activation='relu'))\n",
        "lstm_model.add(Dense(1))\n",
        "\n",
        "# Компиляция модели\n",
        "lstm_model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Обучение модели\n",
        "lstm_model.fit(features_train, target_train, epochs=20, verbose=0)\n",
        "\n",
        "# Прогнозирование на тестовом наборе данных\n",
        "pred = lstm_model.predict(features_test)\n",
        "\n",
        "# Создание DataFrame для хранения результатов\n",
        "res = target_test.to_frame()\n",
        "\n",
        "# Добавление прогнозных значений в DataFrame\n",
        "res['Pred'] = pred\n",
        "\n",
        "# Функция для вычисления WAPE (Weighted Absolute Percentage Error)\n",
        "def wape(y_true: np.array, y_pred: np.array):\n",
        "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))\n",
        "\n",
        "# Вычисление WAPE\n",
        "wape_value = wape(res['pr_sales_in_units'], res['Pred'])"
      ],
      "metadata": {
        "id": "nrLolak7TwmR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}